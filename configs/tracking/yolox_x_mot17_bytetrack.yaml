num_classes: &num_classes 2
runtime:
    aligned: True
    async_norm: True
    special_bn_init: True
    # fp16: True
    fp16:
      keep_batchnorm_fp32: True
      scale_factor: dynamic
    runner:
      type: motfp16
    model_helper:
      type: mot
      kwargs:
        nonref: True

tracker:
  type: bytetracker
  kwargs:
    cfg: 
      track_thresh: 0.6
      track_buffer: 30
      match_thresh: 0.9
      conf_thresh: 0.1


mosaic: &mosaic
  type: mosaic
  kwargs:
    extra_input: True
    tar_size: &tar_size [800, 1440]
    fill_color: 0
    mosaic_self: False
    clip_box: False

random_perspective: &random_perspective
  type: random_perspective_yolox
  kwargs:
    degrees: 10.0 # 0.0
    translate: 0.1
    scale: [0.1, 2.0] # 0.5
    shear: 2.0 # 0.0
    perspective: 0.0
    fill_color: 0  # 0
    border: [-400, -720]
    clip_box: False

augment_hsv: &augment_hsv
  type: augment_hsv
  kwargs:
    hgain: 0.015
    sgain: 0.7
    vgain: 0.4
    color_mode: 'BGR'

mixup: &mixup
  type: yolox_mixup_cv2
  kwargs:
    extra_input: True
    input_size: [800, 1440]
    mixup_scale: [0.8, 1.6]
    fill_color: 0
    clip_box: False

flip: &flip
  type: flip
  kwargs:
    flip_p: 0.5

to_tensor: &to_tensor
  type: custom_to_tensor

train_resize: &train_resize
  type: keep_ar_resize_max
  kwargs:
    #max_size: 640
    #padding_type: left_top
    #padding_val: 0
    random_size: [18, 32]

test_resize: &test_resize
  type: keep_ar_resize_max
  kwargs:
    max_size: 1440
   # padding_type: left_top
   # padding_val: 0

dataset:
  data_pool: ['train:train', 'test:test']
  builder_type: ['base', 'custom']
  train:
    dataset:
      type: custom
      kwargs:
        num_classes: *num_classes
        meta_file: 
           - /mnt/lustre/share_data/qiaolei/datasets/MOT/custom_lists/crowdhuman_new/crowdhuman_train.json
           - /mnt/lustre/share_data/qiaolei/datasets/MOT/custom_lists/crowdhuman_new/crowdhuman_val.json
           - /mnt/lustre/share_data/qiaolei/datasets/MOT/custom_lists/cityscapes/cityscapes_train.json
           - /mnt/lustre/share_data/qiaolei/datasets/MOT/custom_lists/cityscapes/cityscapes_val.json
           - /mnt/lustre/share_data/qiaolei/datasets/MOT/custom_lists/ETHZ/ETHZ.json
           - /mnt/lustre/share_data/qiaolei/datasets/MOT/custom_lists/MOT17/train_half.txt
        image_reader:
          type: fs_opencv
          kwargs:
            image_dir: 
               - /mnt/lustre/share_data/qiaolei/datasets/MOT
               - /mnt/lustre/share_data/qiaolei/datasets/MOT
               - /mnt/lustre/share_data/qiaolei/datasets/MOT
               - /mnt/lustre/share_data/qiaolei/datasets/MOT
               - /mnt/lustre/share_data/qiaolei/datasets/MOT
               - /mnt/lustre/share_data/qiaolei/datasets/MOT
            color_mode: BGR
        transformer: [*mosaic, *random_perspective, *mixup, *augment_hsv, *flip, *train_resize, *to_tensor]
        # cache:
        #      cache_dir: ./caches
        #      cache_name: mot17_mix_train.pkl
        clip_box: False
    batch_sampler:
      type: base
      kwargs:
        sampler:
          type: dist
          kwargs: {}
        batch_size: 4
    dataloader:
      type: base
      kwargs:
        num_workers: 8
        alignment: 32
        worker_init: True
        pad_type: batch_pad
  test:
    dataset:
      type: mot
      kwargs:
        num_classes: *num_classes
        meta_file: &gt_file 
          - /mnt/lustre/share_data/qiaolei/datasets/MOT/MOT20/annotations/train_val.json
        image_reader:
          type: fs_opencv
          kwargs:
            image_dir: 
              - /mnt/lustre/share_data/qiaolei/datasets/MOT
            color_mode: BGR
        transformer: [*test_resize, *to_tensor]
        evaluator:
          type: tracking
          kwargs:
            gt_file: /mnt/lustre/share_data/qiaolei/datasets/MOT/MOT20/annotations/train_val.json
            iou_thresh: 0.5
            fppi: [0.5, 1.0, 1.5, 2.0, 3.0, 4.0]
            num_classes: *num_classes
        #    evaluator:
        #      type: MR
        #      kwargs:
        #        gt_file: *gt_file
        #        iou_thresh: 0.5
        #        fppi: [0.5, 1.0, 1.5, 2.0, 3.0, 4.0]
        #        num_classes: *num_classes
        clip_box: True
        # cache:
        #   cache_dir: ./caches
        #   cache_name: mot20_test.pkl
    batch_sampler:
      type: sequence
      kwargs:
        sampler:
          type: dist_seq
          kwargs: {}
        batch_size: 1
    dataloader:
      type: mot
      kwargs:
        num_workers: 8
        alignment: 32
        worker_init: True
        pad_type: batch_pad
  

trainer: # Required.
  max_epoch: &max_epoch 80             # total epochs for the training
  save_freq: 1
  test_freq: 1
  only_save_latest: True
  optimizer:                 # optimizer = SGD(params,lr=0.01,momentum=0.937,weight_decay=0.0005)
    register_type: yolov5
    type: SGD
    kwargs:
      lr: 0.000015625
      momentum: 0.9
      nesterov: True
      weight_decay: 0.0005
  lr_scheduler:
    lr_register_type: yolox_base
    warmup_epochs: 1       # set to be 0 to disable warmup. When warmup,  target_lr = init_lr * total_batch_size
    warmup_type: yolox_cos
    type: YoloXCosineLR
    kwargs:
      T_max: *max_epoch
      min_lr_scale: 0.05
      no_aug_epoch: &no_aug_epoch 10

saver:
  save_dir: checkpoints/yolox_x_mot17_ori_submit_v1
  pretrain_model: /mnt/lustre/share_data/qiaolei/pretrain/pretrain_models/mot/yolox_ckpt_best.pth
  results_dir: results_dir/yolox_x_mot17_ori_submit_v1
  auto_resume: True
  save_result: True

hooks:
  - type: yolox_noaug
    kwargs:
      no_aug_epoch: *no_aug_epoch
      max_epoch: *max_epoch
      transformer: [*augment_hsv, *flip, *train_resize, *to_tensor]
      test_freq: 2
  - type: auto_save_best

ema:
  enable: True
  ema_type: exp
  kwargs:
    decay: 0.9998

Bn: &Bn
  type: solo_bn
 # kwargs:
 #    bn_group_size: 2

net:
  - name: backbone
    type: yolox_x
    kwargs:
      out_layers: [2, 3, 4]
      out_strides: [8, 16, 32]
      normalize: *Bn
      act_fn: {'type': 'Silu' }
  - name: neck
    prev: backbone
    type: YoloxPAFPN
    kwargs:
      depth: &depth 1.33
      out_strides: [8, 16, 32]
      act_fn: {'type': 'Silu'}
      normalize: *Bn
  - name: roi_head
    prev: neck
    type: YoloXHead
    kwargs:
      num_classes: *num_classes  # number of classes including backgroudn. for rpn, it's 2; for RetinaNet, it's 81
      width: 1.25
      num_point: &dense_points 1
      act_fn: {'type': 'Silu'}
      normalize: *Bn
  - name: yolox_post
    prev: roi_head
    type: yolox_post
    kwargs:
      num_classes: *num_classes  # number of classes including backgroudn. for rpn, it's 2; for RetinaNet, it's 81
      cfg:
        loc_loss:
          type: iou_loss
          kwargs:
            loss_type: square_iou
            loss_weight: 5.0
        cls_loss:
          type: sigmoid_cross_entropy
        obj_loss:
          type: sigmoid_cross_entropy
        anchor_generator:
          type: fcos # yolox
          kwargs:
            dense_points: *dense_points
            center: False
        roi_supervisor:
          type: ota
          kwargs:
            num_classes: *num_classes
            matcher:
              type: ota
              kwargs:
                num_classes: *num_classes
        roi_predictor:
          type: yolox
          kwargs:
            num_classes: *num_classes
            pre_nms_score_thresh: 0.001
            nms:
              type: naive
              nms_iou_thresh: 0.7
